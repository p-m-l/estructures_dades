{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11c5c5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web scraping - Wikipedia\n",
      "#bodyContent\n",
      "/wiki/Main_Page\n",
      "/wiki/Special:Search\n",
      "/w/index.php?title=Special:CreateAccount&returnto=Web+scraping\n",
      "/w/index.php?title=Special:UserLogin&returnto=Web+scraping\n",
      "/w/index.php?title=Special:CreateAccount&returnto=Web+scraping\n",
      "/w/index.php?title=Special:UserLogin&returnto=Web+scraping\n",
      "/wiki/Help:Introduction\n",
      "/wiki/Special:MyTalk\n",
      "/wiki/Special:MyContributions\n",
      "/wiki/Main_Page\n",
      "/wiki/Wikipedia:Contents\n",
      "/wiki/Portal:Current_events\n",
      "/wiki/Special:Random\n",
      "/wiki/Wikipedia:About\n",
      "//en.wikipedia.org/wiki/Wikipedia:Contact_us\n",
      "https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en\n",
      "/wiki/Help:Contents\n",
      "/wiki/Help:Introduction\n",
      "/wiki/Wikipedia:Community_portal\n",
      "/wiki/Special:RecentChanges\n",
      "/wiki/Wikipedia:File_upload_wizard\n",
      "/wiki/Special:WhatLinksHere/Web_scraping\n",
      "/wiki/Special:RecentChangesLinked/Web_scraping\n",
      "/wiki/Wikipedia:File_Upload_Wizard\n",
      "/wiki/Special:SpecialPages\n",
      "/w/index.php?title=Web_scraping&oldid=1137141826\n",
      "/w/index.php?title=Web_scraping&action=info\n",
      "/w/index.php?title=Special:CiteThisPage&page=Web_scraping&id=1137141826&wpFormIdentifier=titleform\n",
      "https://www.wikidata.org/wiki/Special:EntityPage/Q665452\n",
      "/w/index.php?title=Special:DownloadAsPdf&page=Web_scraping&action=show-download-screen\n",
      "/w/index.php?title=Web_scraping&printable=yes\n",
      "#p-lang-btn\n",
      "#\n",
      "#History\n",
      "#Techniques\n",
      "#Human_copy-and-paste\n",
      "#Text_pattern_matching\n",
      "#HTTP_programming\n",
      "#HTML_parsing\n",
      "#DOM_parsing\n",
      "#Vertical_aggregation\n",
      "#Semantic_annotation_recognizing\n",
      "#Computer_vision_web-page_analysis\n",
      "#Software\n",
      "#Legal_issues\n",
      "#United_States\n",
      "#European_Union\n",
      "#Australia\n",
      "#India\n",
      "#Methods_to_prevent_web_scraping\n",
      "#See_also\n",
      "#References\n",
      "https://ar.wikipedia.org/wiki/%D8%AA%D8%AC%D8%B1%D9%8A%D9%81_%D9%88%D9%8A%D8%A8\n",
      "https://ca.wikipedia.org/wiki/Web_scraping\n",
      "https://cs.wikipedia.org/wiki/Web_scraping\n",
      "https://ary.wikipedia.org/wiki/%D8%AA%D8%BA%D8%B1%D8%A7%D9%81_%D9%84%D9%88%D9%8A%D8%A8\n",
      "https://de.wikipedia.org/wiki/Screen_Scraping\n",
      "https://es.wikipedia.org/wiki/Web_scraping\n",
      "https://eu.wikipedia.org/wiki/Web_scraping\n",
      "https://fa.wikipedia.org/wiki/%D9%88%D8%A8_%D8%A7%D8%B3%DA%A9%D8%B1%D9%BE%DB%8C%D9%86%DA%AF\n",
      "https://fr.wikipedia.org/wiki/Web_scraping\n",
      "https://id.wikipedia.org/wiki/Web_scraping\n",
      "https://is.wikipedia.org/wiki/Vefs%C3%B6fnun\n",
      "https://it.wikipedia.org/wiki/Web_scraping\n",
      "https://lv.wikipedia.org/wiki/Rasmo%C5%A1ana\n",
      "https://nl.wikipedia.org/wiki/Scrapen\n",
      "https://ja.wikipedia.org/wiki/%E3%82%A6%E3%82%A7%E3%83%96%E3%82%B9%E3%82%AF%E3%83%AC%E3%82%A4%E3%83%94%E3%83%B3%E3%82%B0\n",
      "https://pt.wikipedia.org/wiki/Coleta_de_dados_web\n",
      "https://ru.wikipedia.org/wiki/%D0%92%D0%B5%D0%B1-%D1%81%D0%BA%D1%80%D0%B5%D0%B9%D0%BF%D0%B8%D0%BD%D0%B3\n",
      "https://tr.wikipedia.org/wiki/Web_kaz%C4%B1ma\n",
      "https://uk.wikipedia.org/wiki/Web_scraping\n",
      "https://zh-yue.wikipedia.org/wiki/%E7%B6%B2%E9%A0%81%E5%88%AE%E6%96%99\n",
      "https://zh.wikipedia.org/wiki/%E7%BD%91%E9%A1%B5%E6%8A%93%E5%8F%96\n",
      "https://www.wikidata.org/wiki/Special:EntityPage/Q665452#sitelinks-wikipedia\n",
      "/wiki/Web_scraping\n",
      "/wiki/Talk:Web_scraping\n",
      "/wiki/Web_scraping\n",
      "/w/index.php?title=Web_scraping&action=edit\n",
      "/w/index.php?title=Web_scraping&action=history\n",
      "/wiki/Web_scraping\n",
      "/w/index.php?title=Web_scraping&action=edit\n",
      "/w/index.php?title=Web_scraping&action=history\n",
      "/wiki/File:Question_book-new.svg\n",
      "/wiki/Wikipedia:Verifiability\n",
      "https://en.wikipedia.org/w/index.php?title=Web_scraping&action=edit\n",
      "/wiki/Help:Referencing_for_beginners\n",
      "//www.google.com/search?as_eq=wikipedia&q=%22Web+scraping%22\n",
      "//www.google.com/search?tbm=nws&q=%22Web+scraping%22+-wikipedia&tbs=ar:1\n",
      "//www.google.com/search?&q=%22Web+scraping%22&tbs=bkt:s&tbm=bks\n",
      "//www.google.com/search?tbs=bks:1&q=%22Web+scraping%22+-wikipedia\n",
      "//scholar.google.com/scholar?q=%22Web+scraping%22\n",
      "https://www.jstor.org/action/doBasicSearch?Query=%22Web+scraping%22&acc=on&wc=on\n",
      "/wiki/Help:Maintenance_template_removal\n",
      "/wiki/Data_scraping\n",
      "/wiki/Data_scraping\n",
      "/wiki/Data_extraction\n",
      "/wiki/Website\n",
      "#cite_note-1\n",
      "/wiki/World_Wide_Web\n",
      "/wiki/Hypertext_Transfer_Protocol\n",
      "/wiki/Internet_bot\n",
      "/wiki/Web_crawler\n",
      "/wiki/Database\n",
      "/wiki/Data_retrieval\n",
      "/wiki/Data_analysis\n",
      "/wiki/Parsing\n",
      "/wiki/Contact_scraping\n",
      "/wiki/Web_indexing\n",
      "/wiki/Web_mining\n",
      "/wiki/Data_mining\n",
      "/wiki/Comparison_shopping_website\n",
      "/wiki/Change_detection_and_notification\n",
      "/wiki/Web_mashup\n",
      "/wiki/Web_data_integration\n",
      "/wiki/Web_page\n",
      "/wiki/HTML\n",
      "/wiki/XHTML\n",
      "/wiki/End-user_(computer_science)\n",
      "/wiki/JSON\n",
      "/wiki/Document_Object_Model\n",
      "/wiki/Computer_vision\n",
      "/wiki/Natural_language_processing\n",
      "/w/index.php?title=Web_scraping&action=edit&section=1\n",
      "/wiki/File:Question_book-new.svg\n",
      "/wiki/Wikipedia:Citing_sources\n",
      "/wiki/Wikipedia:Verifiability\n",
      "https://en.wikipedia.org/w/index.php?title=Web_scraping&action=edit\n",
      "/wiki/Help:Referencing_for_beginners\n",
      "/wiki/Wikipedia:Verifiability#Burden_of_evidence\n",
      "/wiki/Help:Maintenance_template_removal\n",
      "/wiki/History_of_the_World_Wide_Web\n",
      "#cite_note-2\n",
      "/wiki/World_Wide_Web_Wanderer\n",
      "/wiki/JumpStation\n",
      "/wiki/Application_programming_interface\n",
      "/wiki/Salesforce.com\n",
      "/wiki/EBay\n",
      "/w/index.php?title=Web_scraping&action=edit&section=2\n",
      "/wiki/Semantic_web\n",
      "/wiki/Human-computer_interaction\n",
      "/w/index.php?title=Web_scraping&action=edit&section=3\n",
      "/w/index.php?title=Web_scraping&action=edit&section=4\n",
      "/wiki/Grep\n",
      "/wiki/Regular_expression\n",
      "/wiki/Perl\n",
      "/wiki/Python_(programming_language)\n",
      "/w/index.php?title=Web_scraping&action=edit&section=5\n",
      "/wiki/Static_web_page\n",
      "/wiki/Dynamic_web_page\n",
      "/wiki/Socket_programming\n",
      "/w/index.php?title=Web_scraping&action=edit&section=6\n",
      "/wiki/Wrapper_(data_mining)\n",
      "#cite_note-3\n",
      "/wiki/Semi-structured_data\n",
      "/wiki/XQuery\n",
      "/w/index.php?title=Web_scraping&action=edit&section=7\n",
      "/wiki/Document_Object_Model\n",
      "/wiki/Internet_Explorer\n",
      "/wiki/Mozilla\n",
      "/wiki/XPath\n",
      "/w/index.php?title=Web_scraping&action=edit&section=8\n",
      "/wiki/Long_Tail\n",
      "/w/index.php?title=Web_scraping&action=edit&section=9\n",
      "/wiki/Metadata\n",
      "/wiki/Microformat\n",
      "#cite_note-4\n",
      "/w/index.php?title=Web_scraping&action=edit&section=10\n",
      "/wiki/Machine_learning\n",
      "/wiki/Computer_vision\n",
      "#cite_note-5\n",
      "/w/index.php?title=Web_scraping&action=edit&section=11\n",
      "/w/index.php?title=Web_scraping&action=edit&section=12\n",
      "/wiki/Wikipedia:WikiProject_Countering_systemic_bias\n",
      "https://en.wikipedia.org/w/index.php?title=Web_scraping&action=edit\n",
      "/wiki/Talk:Web_scraping\n",
      "/wiki/Help:Maintenance_template_removal\n",
      "/wiki/Terms_of_use\n",
      "#cite_note-6\n",
      "/w/index.php?title=Web_scraping&action=edit&section=13\n",
      "/wiki/Cause_of_action\n",
      "/wiki/Computer_Fraud_and_Abuse_Act\n",
      "/wiki/Trespass_to_chattels\n",
      "#cite_note-7\n",
      "/wiki/Feist_Publications,_Inc.,_v._Rural_Telephone_Service_Co.\n",
      "/wiki/Trespass_to_chattels\n",
      "#cite_note-8\n",
      "#cite_note-9\n",
      "/wiki/EBay_v._Bidder%27s_Edge\n",
      "/wiki/Auction_sniping\n",
      "/wiki/Personal_property\n",
      "/wiki/Plaintiff\n",
      "/wiki/Defendant\n",
      "#cite_note-10\n",
      "/wiki/Screen_scraping\n",
      "/wiki/American_Airlines\n",
      "#cite_note-11\n",
      "/wiki/Injunction\n",
      "#cite_note-12\n",
      "/wiki/Southwest_Airlines\n",
      "/wiki/US_Copyright_law\n",
      "/wiki/Supreme_Court_of_the_United_States\n",
      "/wiki/Yahoo!\n",
      "#cite_note-impervawp2011-13\n",
      "/wiki/Craigslist_v._3Taps\n",
      "/wiki/Computer_Fraud_and_Abuse_Act\n",
      "#cite_note-14\n",
      "/wiki/Cvent,_Inc.\n",
      "/wiki/Eventbrite\n",
      "/wiki/Browse_wrap\n",
      "#cite_note-15\n",
      "/wiki/United_States_District_Court_for_the_Eastern_District_of_Pennsylvania\n",
      "#cite_note-16\n",
      "/wiki/QVC\n",
      "#cite_note-17\n",
      "#cite_note-18\n",
      "/wiki/Facebook,_Inc._v._Power_Ventures,_Inc.\n",
      "/wiki/Electronic_Frontier_Foundation\n",
      "#cite_note-19\n",
      "#cite_note-20\n",
      "/wiki/Associated_Press_v._Meltwater_U.S._Holdings,_Inc.\n",
      "/wiki/Internet_Archive\n",
      "/w/index.php?title=Web_scraping&action=edit&section=14\n",
      "/wiki/Maritime_and_Commercial_Court_(Denmark)\n",
      "#cite_note-21\n",
      "/wiki/Inchoate_offense\n",
      "/wiki/Ryanair\n",
      "/wiki/Clickwrap\n",
      "/wiki/Michael_Hanna_(judge)\n",
      "#cite_note-22\n",
      "#cite_note-23\n",
      "#cite_note-24\n",
      "#cite_note-25\n",
      "/w/index.php?title=Web_scraping&action=edit&section=15\n",
      "/wiki/Spam_Act_2003\n",
      "#cite_note-26\n",
      "#cite_note-27\n",
      "/w/index.php?title=Web_scraping&action=edit&section=16\n",
      "/wiki/Information_Technology_Act,_2000#:~:text=From_Wikipedia,_the_free_encyclopedia_The_Information_Technology,in_India_dealing_with_cybercrime_and_electronic_commerce.\n",
      "/w/index.php?title=Web_scraping&action=edit&section=17\n",
      "/wiki/IP_address\n",
      "/wiki/Geolocation\n",
      "/wiki/DNSBL\n",
      "/wiki/Web_service\n",
      "/wiki/Application_programming_interface\n",
      "/wiki/User_agent\n",
      "/wiki/String_(computer_science)\n",
      "/wiki/Robots_exclusion_standard\n",
      "/wiki/Googlebot\n",
      "/wiki/CAPTCHA\n",
      "/wiki/Application_firewall\n",
      "#cite_note-28\n",
      "/wiki/Honeypot_(computing)\n",
      "/wiki/Obfuscation\n",
      "/wiki/CSS_sprite\n",
      "/wiki/Web_accessibility\n",
      "/wiki/Screen_reader\n",
      "/wiki/Robots_exclusion_standard\n",
      "/wiki/AJAX\n",
      "/wiki/Headless_browser\n",
      "/w/index.php?title=Web_scraping&action=edit&section=18\n",
      "/wiki/Archive.today\n",
      "/wiki/Comparison_of_feed_aggregators\n",
      "/wiki/Data_scraping\n",
      "/wiki/Data_wrangling\n",
      "/wiki/Importer_(computing)\n",
      "/wiki/Job_wrapping\n",
      "/wiki/Knowledge_extraction\n",
      "/wiki/OpenSocial\n",
      "/wiki/Scraper_site\n",
      "/wiki/Fake_news_website\n",
      "/wiki/Blog_scraping\n",
      "/wiki/Spamdexing\n",
      "/wiki/Domain_name_drop_list\n",
      "/wiki/Text_corpus\n",
      "/wiki/Web_archiving\n",
      "/wiki/Web_crawler\n",
      "/wiki/Offline_reader\n",
      "/wiki/Link_farm\n",
      "/wiki/Search_engine_scraping\n",
      "/wiki/Category:Web_crawlers\n",
      "/w/index.php?title=Web_scraping&action=edit&section=19\n",
      "#cite_ref-1\n",
      "http://datascience.codata.org/articles/10.5334/dsj-2021-024/\n",
      "/wiki/Doi_(identifier)\n",
      "https://doi.org/10.5334%2Fdsj-2021-024\n",
      "/wiki/ISSN_(identifier)\n",
      "https://www.worldcat.org/issn/1683-1470\n",
      "/wiki/S2CID_(identifier)\n",
      "https://api.semanticscholar.org/CorpusID:237719804\n",
      "#cite_ref-2\n",
      "http://www.searchenginehistory.com/\n",
      "#cite_ref-3\n",
      "https://web.archive.org/web/20161011080619/https://pdfs.semanticscholar.org/4fb4/3c5a212df751e84c3b2f8d29fabfe56c3616.pdf\n",
      "/wiki/Doi_(identifier)\n",
      "https://doi.org/10.1145%2F1281192.1281287\n",
      "/wiki/ISBN_(identifier)\n",
      "/wiki/Special:BookSources/9781595936097\n",
      "/wiki/S2CID_(identifier)\n",
      "https://api.semanticscholar.org/CorpusID:833565\n",
      "https://pdfs.semanticscholar.org/4fb4/3c5a212df751e84c3b2f8d29fabfe56c3616.pdf\n",
      "#cite_ref-4\n",
      "http://www.gooseeker.com/en/node/knowledgebase/freeformat\n",
      "#cite_ref-5\n",
      "http://www.xconomy.com/san-francisco/2012/07/25/diffbot-is-using-computer-vision-to-reinvent-the-semantic-web/\n",
      "#cite_ref-6\n",
      "https://web.archive.org/web/20020308222536/http://www.chillingeffects.org/linking/faq.cgi#QID596\n",
      "http://www.chillingeffects.org/linking/faq.cgi#QID596\n",
      "#cite_ref-7\n",
      "http://scholarship.law.berkeley.edu/btlj/vol29/iss4/16/\n",
      "/wiki/Doi_(identifier)\n",
      "https://doi.org/10.15779%2FZ38B39B\n",
      "/wiki/ISSN_(identifier)\n",
      "https://www.worldcat.org/issn/1086-3818\n",
      "#cite_ref-8\n",
      "http://www.tomwbell.com/NetLaw/Ch06.html\n",
      "#cite_ref-9\n",
      "https://web.archive.org/web/20020308222536/http://www.chillingeffects.org/linking/faq.cgi#QID460\n",
      "http://www.chillingeffects.org/linking/faq.cgi#QID460\n",
      "#cite_ref-10\n",
      "http://www.tomwbell.com/NetLaw/Ch07/Ticketmaster.html\n",
      "#cite_ref-11\n",
      "https://web.archive.org/web/20110723131832/http://www.fornova.net/documents/AAFareChase.pdf\n",
      "http://www.fornova.net/documents/AAFareChase.pdf\n",
      "#cite_ref-12\n",
      "http://www.thefreelibrary.com/American+Airlines,+FareChase+Settle+Suit.-a0103213546\n",
      "#cite_ref-impervawp2011_13-0\n",
      "http://www.imperva.com/docs/WP_Detecting_and_Blocking_Site_Scraping_Attacks.pdf\n",
      "#cite_ref-14\n",
      "https://web.archive.org/web/20110211123854/http://library.findlaw.com/2003/Jul/29/132944.html\n",
      "http://library.findlaw.com/2003/Jul/29/132944.html\n",
      "#cite_ref-15\n",
      "http://www.fornova.net/documents/Cvent.pdf\n",
      "#cite_ref-16\n",
      "https://www.scribd.com/doc/249068700/LinkedIn-v-Resultly-LLC-Complaint?secret_password=pEVKDbnvhQL52oKfdrmT\n",
      "#cite_ref-17\n",
      "http://newmedialaw.proskauer.com/2014/12/05/qvc-sues-shopping-app-for-web-scraping-that-allegedly-triggered-site-outage/\n",
      "#cite_ref-18\n",
      "http://www.fornova.net/documents/pblog-bna-com.pdf\n",
      "#cite_ref-19\n",
      "https://www.techdirt.com/articles/20090605/2228205147.shtml\n",
      "#cite_ref-20\n",
      "https://www.eff.org/cases/facebook-v-power-ventures\n",
      "#cite_ref-21\n",
      "https://web.archive.org/web/20071012005033/http://www.bvhd.dk/uploads/tx_mocarticles/S_-_og_Handelsrettens_afg_relse_i_Ofir-sagen.pdf\n",
      "http://www.bvhd.dk/uploads/tx_mocarticles/S_-_og_Handelsrettens_afg_relse_i_Ofir-sagen.pdf\n",
      "#cite_ref-22\n",
      "http://www.bailii.org/ie/cases/IEHC/2010/H47.html\n",
      "#cite_ref-23\n",
      "http://www.lkshields.ie/htmdocs/publications/newsletters/update26/update26_03.htm\n",
      "#cite_ref-24\n",
      "https://www.cnil.fr/fr/la-reutilisation-des-donnees-publiquement-accessibles-en-ligne-des-fins-de-demarchage-commercial\n",
      "#cite_ref-25\n",
      "https://medium.com/@finddatalab/can-you-still-perform-web-scraping-with-the-new-cnil-guidelines-bf3e20d0edc2\n",
      "#cite_ref-26\n",
      "https://www.lloyds.com/~/media/5880dae185914b2487bed7bd63b96286.ashx\n",
      "#cite_ref-27\n",
      "http://www.webstartdesign.com.au/spam_business_practical_guide.pdf\n",
      "#cite_ref-28\n",
      "https://s3.us-west-2.amazonaws.com/research-papers-mynk/Breaking-Fraud-And-Bot-Detection-Solutions.pdf\n",
      "https://en.wikipedia.org/w/index.php?title=Web_scraping&oldid=1137141826\n",
      "/wiki/Help:Category\n",
      "/wiki/Category:Web_scraping\n",
      "/wiki/Category:CS1_Danish-language_sources_(da)\n",
      "/wiki/Category:CS1_French-language_sources_(fr)\n",
      "/wiki/Category:Articles_with_short_description\n",
      "/wiki/Category:Short_description_matches_Wikidata\n",
      "/wiki/Category:Articles_needing_additional_references_from_June_2017\n",
      "/wiki/Category:All_articles_needing_additional_references\n",
      "/wiki/Category:Articles_needing_additional_references_from_October_2018\n",
      "/wiki/Category:Articles_with_limited_geographic_scope_from_October_2015\n",
      "/wiki/Category:United_States-centric\n",
      "//en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License\n",
      "//creativecommons.org/licenses/by-sa/3.0/\n",
      "//foundation.wikimedia.org/wiki/Terms_of_Use\n",
      "//foundation.wikimedia.org/wiki/Privacy_policy\n",
      "//www.wikimediafoundation.org/\n",
      "https://foundation.wikimedia.org/wiki/Privacy_policy\n",
      "/wiki/Wikipedia:About\n",
      "/wiki/Wikipedia:General_disclaimer\n",
      "//en.wikipedia.org/wiki/Wikipedia:Contact_us\n",
      "//en.m.wikipedia.org/w/index.php?title=Web_scraping&mobileaction=toggle_view_mobile\n",
      "https://developer.wikimedia.org\n",
      "https://stats.wikimedia.org/#/en.wikipedia.org\n",
      "https://foundation.wikimedia.org/wiki/Cookie_statement\n",
      "https://wikimediafoundation.org/\n",
      "https://www.mediawiki.org/\n"
     ]
    }
   ],
   "source": [
    "# Exercici 1\n",
    "\n",
    "# Utilizant BeautifulSoup\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/Web_scraping'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Get the title of the page\n",
    "title = soup.title.text\n",
    "print(title)\n",
    "\n",
    "# Find all the links in the page\n",
    "links = soup.find_all('a')\n",
    "for link in links:\n",
    "    print(link.get('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb010c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quotes to Scrape\n",
      "/\n",
      "/login\n",
      "/author/Albert-Einstein\n",
      "/tag/change/page/1/\n",
      "/tag/deep-thoughts/page/1/\n",
      "/tag/thinking/page/1/\n",
      "/tag/world/page/1/\n",
      "/author/J-K-Rowling\n",
      "/tag/abilities/page/1/\n",
      "/tag/choices/page/1/\n",
      "/author/Albert-Einstein\n",
      "/tag/inspirational/page/1/\n",
      "/tag/life/page/1/\n",
      "/tag/live/page/1/\n",
      "/tag/miracle/page/1/\n",
      "/tag/miracles/page/1/\n",
      "/author/Jane-Austen\n",
      "/tag/aliteracy/page/1/\n",
      "/tag/books/page/1/\n",
      "/tag/classic/page/1/\n",
      "/tag/humor/page/1/\n",
      "/author/Marilyn-Monroe\n",
      "/tag/be-yourself/page/1/\n",
      "/tag/inspirational/page/1/\n",
      "/author/Albert-Einstein\n",
      "/tag/adulthood/page/1/\n",
      "/tag/success/page/1/\n",
      "/tag/value/page/1/\n",
      "/author/Andre-Gide\n",
      "/tag/life/page/1/\n",
      "/tag/love/page/1/\n",
      "/author/Thomas-A-Edison\n",
      "/tag/edison/page/1/\n",
      "/tag/failure/page/1/\n",
      "/tag/inspirational/page/1/\n",
      "/tag/paraphrased/page/1/\n",
      "/author/Eleanor-Roosevelt\n",
      "/tag/misattributed-eleanor-roosevelt/page/1/\n",
      "/author/Steve-Martin\n",
      "/tag/humor/page/1/\n",
      "/tag/obvious/page/1/\n",
      "/tag/simile/page/1/\n",
      "/page/2/\n",
      "/tag/love/\n",
      "/tag/inspirational/\n",
      "/tag/life/\n",
      "/tag/humor/\n",
      "/tag/books/\n",
      "/tag/reading/\n",
      "/tag/friendship/\n",
      "/tag/friends/\n",
      "/tag/truth/\n",
      "/tag/simile/\n",
      "https://www.goodreads.com/quotes\n",
      "https://scrapinghub.com\n"
     ]
    }
   ],
   "source": [
    "url = 'https://quotes.toscrape.com/'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Get the title of the page\n",
    "title = soup.title.text\n",
    "print(title)\n",
    "\n",
    "# Find all the links in the page\n",
    "links = soup.find_all('a')\n",
    "for link in links:\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7076149a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"c3a3cca7157f3fc17acf80365ca153d9\", element=\"8d41544c-26bd-4101-8297-3272cf46a544\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c3a3cca7157f3fc17acf80365ca153d9\", element=\"432a55f7-eca3-46ba-a7f0-abe40b249477\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"c3a3cca7157f3fc17acf80365ca153d9\", element=\"0367e14a-48f0-4724-8e2f-3cc594889c09\")>]\n",
      "\n",
      "NOTA: la llibreria selenium no és molt user friendly i han canviat recentment les maneres \n",
      "de fer el web scrapping.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# create webdriver object\n",
    "driver = webdriver.Chrome()\n",
    " \n",
    "# get geeksforgeeks.org\n",
    "driver.get(\"https://en.wikipedia.org/wiki/Web_scraping\")\n",
    " \n",
    "# get element\n",
    "element = driver.find_elements(By.PARTIAL_LINK_TEXT, 'World Wide Web')\n",
    " \n",
    "# print complete element\n",
    "print(element)\n",
    "print(\"\"\"\\nNOTA: la llibreria selenium no és molt user friendly i han canviat recentment les maneres \n",
    "de fer el web scrapping.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9139f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXERCICI 2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the wikipedia table into pandas dataset\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\"\n",
    "dfs = pd.read_html(url)\n",
    "df = dfs[0]\n",
    "#df = pd.DataFrame(df).iloc[1:].set_index('Rank')\n",
    "\n",
    "# Save the dataset as an excel file\n",
    "df.to_excel(\"highest_grossing_films.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d200db6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Link\n",
      "ID                                       \n",
      "[# 1]                #cite_note-avatar-13\n",
      "[# 2]           #cite_note-avatar_peak-14\n",
      "[# 3]               #cite_note-endgame-15\n",
      "[# 4]          #cite_note-endgame_peak-16\n",
      "[# 5]               #cite_note-avatar2-17\n",
      "[# 6]                       #cite_note-18\n",
      "[# 7]               #cite_note-titanic-19\n",
      "[# 8]          #cite_note-titanic_peak-20\n",
      "[# 9]                   #cite_note-sw7-21\n",
      "[# 10]             #cite_note-sw7_peak-22\n",
      "[# 11]         #cite_note-infinity_war-23\n",
      "[# 12]    #cite_note-infinity_war_peak-24\n",
      "[# 13]                  #cite_note-nwh-25\n",
      "[# 14]     #cite_note-No_Way_Home_peak-26\n",
      "[# 15]       #cite_note-jurassic_world-27\n",
      "[# 16]  #cite_note-jurassic_world_peak-28\n",
      "[# 17]                      #cite_note-29\n",
      "[# 18]             #cite_note-avengers-30\n",
      "[# 19]        #cite_note-avengers_peak-31\n",
      "[# 20]                #cite_note-fast7-32\n",
      "[# 21]       #cite_note-furious_7_peak-33\n",
      "[# 22]                  #cite_note-tgm-34\n",
      "[# 23]        #cite_note-Maverick_peak-35\n",
      "[# 24]                      #cite_note-36\n",
      "[# 25]           #cite_note-covid_peak-37\n",
      "[# 26]                      #cite_note-38\n",
      "[# 27]        #cite_note-black_panther-39\n",
      "[# 28]                      #cite_note-40\n",
      "[# 29]                #cite_note-hp7.2-41\n",
      "[# 30]             #cite_note-HP8_peak-42\n",
      "[# 31]                  #cite_note-sw8-43\n",
      "[# 32]             #cite_note-SW8_peak-44\n",
      "[# 33]                      #cite_note-45\n",
      "[# 34]               #cite_note-Frozen-46\n",
      "[# 35]          #cite_note-frozen_peak-47\n",
      "[# 36]               #cite_note-beauty-48\n",
      "[# 37]          #cite_note-Beauty_peak-49\n",
      "[# 38]                      #cite_note-50\n",
      "[# 39]                      #cite_note-51\n",
      "[# 40]           #cite_note-iron_man_3-52\n",
      "[# 41]      #cite_note-iron_man_3_peak-53\n",
      "[# 42]                      #cite_note-54\n",
      "[# 43]            #cite_note-civil_war-55\n",
      "[# 44]       #cite_note-civil_war_peak-56\n",
      "[# 45]                      #cite_note-57\n",
      "[# 46]                #cite_note-lotr3-58\n",
      "[# 47]            #cite_note-ROTK_peak-59\n",
      "[# 48]                      #cite_note-60\n",
      "[# 49]       #cite_note-captain_marvel-61\n",
      "[# 50]  #cite_note-captain_marvel_peak-62\n",
      "[# 51]                      #cite_note-63\n",
      "[# 52]                      #cite_note-64\n",
      "[# 53]         #cite_note-Skyfall_peak-65\n",
      "[# 54]         #cite_note-transformers-66\n",
      "[# 55]  #cite_note-Transformers_4_peak-67\n",
      "[# 56]                      #cite_note-68\n",
      "[# 57]       #cite_note-Ice_Age_3_peak-69\n",
      "[# 58]                      #cite_note-70\n",
      "[# 59]                      #cite_note-71\n",
      "[# 60]                      #cite_note-72\n",
      "[# 61]                  #cite_note-ts3-73\n",
      "[# 62]     #cite_note-toy_story_3_peak-74\n",
      "[# 63]                #cite_note-potc2-75\n",
      "[# 64]          #cite_note-POTC_2_peak-76\n",
      "[# 65]                      #cite_note-77\n",
      "[# 66]       #cite_note-rogue_one_peak-78\n",
      "[# 67]                      #cite_note-79\n",
      "[# 68]                      #cite_note-80\n",
      "[# 69]                      #cite_note-81\n",
      "[# 70]                   #cite_note-jp-82\n",
      "[# 71]   #cite_note-Jurassic_Park_peak-83\n",
      "[# 72]                      #cite_note-84\n",
      "[# 73]            #cite_note-Dory_peak-85\n",
      "[# 74]                  #cite_note-tpm-86\n",
      "[# 75]                      #cite_note-87\n",
      "[# 76]           #cite_note-Alice_peak-88\n",
      "[# 77]             #cite_note-zootopia-89\n",
      "[# 78]                      #cite_note-90\n",
      "[# 79]        #cite_note-Hobbit_1_peak-91\n",
      "[# 80]                  #cite_note-hp1-92\n",
      "[# 81]             #cite_note-HP1_peak-93\n",
      "[# 82]                  #cite_note-tdk-94\n",
      "[# 83]             #cite_note-TDK_peak-95\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# send request to the wikipedia page\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_highest-grossing_films'\n",
    "response = requests.get(url)\n",
    "\n",
    "# parse the html using beautiful soup and store in variable `soup`\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# find the table containing the references\n",
    "ref_table = soup.find('table', {'class': 'wikitable sortable plainrowheaders'})\n",
    "\n",
    "# extract the reference links\n",
    "ref_links = ref_table.find_all('sup')\n",
    "\n",
    "# create a list of dictionaries containing the reference ID and link\n",
    "ref_list = []\n",
    "for ref in ref_links:\n",
    "    ref_id = ref.text.strip()\n",
    "    ref_link = ref.find('a')\n",
    "    if ref_link is not None and ref_link.get('href').startswith('#cite_note'):\n",
    "        ref_link = ref_link.get('href')\n",
    "        ref_list.append({'ID': ref_id, 'Link': ref_link})\n",
    "\n",
    "# create a dataframe from the list of dictionaries\n",
    "ref_df = pd.DataFrame(ref_list).iloc[1:]\n",
    "\n",
    "# create a dataframe from the list of dictionaries\n",
    "ref_df = pd.DataFrame(ref_list).iloc[1:].set_index('ID')\n",
    "\n",
    "ref_df.drop_duplicates(subset=['Link'], inplace=True)\n",
    "\n",
    "# display the dataframe\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(ref_df)\n",
    "    \n",
    "# Save the dataset as an excel file\n",
    "#ref_df.to_excel(\"REF_highest_grossing_films.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb811909",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                Link\n",
      "ID                                                                                  \n",
      "cite_ref-avatar_13-0               https://web.archive.org/web/20230111202451/htt...\n",
      "cite_ref-avatar_peak_14-0          https://web.archive.org/web/20101103063039/htt...\n",
      "cite_ref-endgame_15-0              https://web.archive.org/web/20230107074435/htt...\n",
      "cite_ref-endgame_peak_16-0         https://web.archive.org/web/20191023105800/htt...\n",
      "cite_ref-avatar2_17-0                 https://www.boxofficemojo.com/title/tt1630029/\n",
      "cite_ref-18                        https://www.the-numbers.com/movie/Avatar-The-W...\n",
      "cite_ref-titanic_19-0              https://web.archive.org/web/20191027003338/htt...\n",
      "cite_ref-titanic_peak_20-0         https://web.archive.org/web/20010716094602/htt...\n",
      "cite_ref-sw7_21-0                  https://www.boxofficemojo.com/releasegroup/gr3...\n",
      "cite_ref-sw7_peak_22-0             https://web.archive.org/web/20160405200403/htt...\n",
      "cite_ref-infinity_war_23-0         https://www.boxofficemojo.com/releasegroup/gr3...\n",
      "cite_ref-infinity_war_peak_24-0    https://web.archive.org/web/20190401194157/htt...\n",
      "cite_ref-nwh_25-0                    https://www.boxofficemojo.com/title/tt10872600/\n",
      "cite_ref-No_Way_Home_peak_26-0     https://web.archive.org/web/20220729144809/htt...\n",
      "cite_ref-jurassic_world_27-0          https://www.boxofficemojo.com/title/tt0369610/\n",
      "cite_ref-jurassic_world_peak_28-0  https://web.archive.org/web/20151126172916/htt...\n",
      "cite_ref-29                        https://www.boxofficemojo.com/releasegroup/gr4...\n",
      "cite_ref-endgame_peak_16-1         https://web.archive.org/web/20191023105800/htt...\n",
      "cite_ref-avengers_30-0             https://web.archive.org/web/20230106134914/htt...\n",
      "cite_ref-avengers_peak_31-0        https://web.archive.org/web/20121001185608/htt...\n",
      "cite_ref-fast7_32-0                   https://www.boxofficemojo.com/title/tt2820852/\n",
      "cite_ref-furious_7_peak_33-0       https://web.archive.org/web/20150626115331/htt...\n",
      "cite_ref-tgm_34-0                     https://www.boxofficemojo.com/title/tt1745960/\n",
      "cite_ref-Maverick_peak_35-0        https://web.archive.org/web/20221229140535/htt...\n",
      "cite_ref-36                        https://www.boxofficemojo.com/release/rl242421...\n",
      "cite_ref-covid_peak_37-0           https://web.archive.org/web/20200801201335/htt...\n",
      "cite_ref-38                        https://web.archive.org/web/20221218222910/htt...\n",
      "cite_ref-furious_7_peak_33-1       https://web.archive.org/web/20150626115331/htt...\n",
      "cite_ref-black_panther_39-0        https://web.archive.org/web/20200830210202/htt...\n",
      "cite_ref-40                        https://web.archive.org/web/20180701190816/htt...\n",
      "cite_ref-hp7.2_41-0                   https://www.boxofficemojo.com/title/tt1201607/\n",
      "cite_ref-HP8_peak_42-0             https://web.archive.org/web/20111031012438/htt...\n",
      "cite_ref-sw8_43-0                  https://www.boxofficemojo.com/releasegroup/gr3...\n",
      "cite_ref-SW8_peak_44-0             https://web.archive.org/web/20180427125111/htt...\n",
      "cite_ref-45                           https://www.boxofficemojo.com/title/tt4881806/\n",
      "cite_ref-infinity_war_peak_24-1    https://web.archive.org/web/20190401194157/htt...\n",
      "cite_ref-Frozen_46-0               https://web.archive.org/web/20140809232736/htt...\n",
      "cite_ref-frozen_peak_47-0          https://web.archive.org/web/20140702050222/htt...\n",
      "cite_ref-beauty_48-0               https://www.boxofficemojo.com/releasegroup/gr1...\n",
      "cite_ref-Beauty_peak_49-0          https://web.archive.org/web/20171211010216/htt...\n",
      "cite_ref-50                        https://www.boxofficemojo.com/releasegroup/gr2...\n",
      "cite_ref-infinity_war_peak_24-2    https://web.archive.org/web/20190401194157/htt...\n",
      "cite_ref-51                        https://web.archive.org/web/20170822151827/htt...\n",
      "cite_ref-Beauty_peak_49-1          https://web.archive.org/web/20171211010216/htt...\n",
      "cite_ref-iron_man_3_52-0           https://www.boxofficemojo.com/release/rl153265...\n",
      "cite_ref-iron_man_3_peak_53-0      https://web.archive.org/web/20140221101228/htt...\n",
      "cite_ref-54                           https://www.boxofficemojo.com/title/tt2293640/\n",
      "cite_ref-jurassic_world_peak_28-1  https://web.archive.org/web/20151126172916/htt...\n",
      "cite_ref-civil_war_55-0            https://web.archive.org/web/20230106231628/htt...\n",
      "cite_ref-civil_war_peak_56-0       https://web.archive.org/web/20160801231148/htt...\n",
      "cite_ref-57                           https://www.boxofficemojo.com/title/tt1477834/\n",
      "cite_ref-infinity_war_peak_24-3    https://web.archive.org/web/20190401194157/htt...\n",
      "cite_ref-lotr3_58-0                   https://www.boxofficemojo.com/title/tt0167260/\n",
      "cite_ref-ROTK_peak_59-0            https://web.archive.org/web/20040605104640/htt...\n",
      "cite_ref-60                           https://www.boxofficemojo.com/title/tt6320628/\n",
      "cite_ref-endgame_peak_16-2         https://web.archive.org/web/20191023105800/htt...\n",
      "cite_ref-captain_marvel_61-0       https://www.boxofficemojo.com/releasegroup/gr3...\n",
      "cite_ref-captain_marvel_peak_62-0  https://web.archive.org/web/20190723022509/htt...\n",
      "cite_ref-63                           https://www.boxofficemojo.com/title/tt1399103/\n",
      "cite_ref-HP8_peak_42-1             https://web.archive.org/web/20111031012438/htt...\n",
      "cite_ref-64                        https://web.archive.org/web/20221017023424/htt...\n",
      "cite_ref-Skyfall_peak_65-0         https://web.archive.org/web/20130303064100/htt...\n",
      "cite_ref-transformers_66-0            https://www.boxofficemojo.com/title/tt2109248/\n",
      "cite_ref-Transformers_4_peak_67-0  https://web.archive.org/web/20141102142043/htt...\n",
      "cite_ref-68                           https://www.boxofficemojo.com/title/tt1345836/\n",
      "cite_ref-Ice_Age_3_peak_69-0       https://web.archive.org/web/20121203161005/htt...\n",
      "cite_ref-70                           https://www.boxofficemojo.com/title/tt7286456/\n",
      "cite_ref-covid_peak_37-1           https://web.archive.org/web/20200801201335/htt...\n",
      "cite_ref-71                        https://www.boxofficemojo.com/release/rl330514...\n",
      "cite_ref-covid_peak_37-2           https://web.archive.org/web/20200801201335/htt...\n",
      "cite_ref-72                        https://www.boxofficemojo.com/release/rl379850...\n",
      "cite_ref-endgame_peak_16-3         https://web.archive.org/web/20191023105800/htt...\n",
      "cite_ref-ts3_73-0                  https://web.archive.org/web/20230106231628/htt...\n",
      "cite_ref-toy_story_3_peak_74-0     https://web.archive.org/web/20110718213347/htt...\n",
      "cite_ref-potc2_75-0                   https://www.boxofficemojo.com/title/tt0383574/\n",
      "cite_ref-POTC_2_peak_76-0          https://web.archive.org/web/20061201034741/htt...\n",
      "cite_ref-77                           https://www.boxofficemojo.com/title/tt3748528/\n",
      "cite_ref-rogue_one_peak_78-0       https://web.archive.org/web/20170419162412/htt...\n",
      "cite_ref-79                        https://www.boxofficemojo.com/release/rl324636...\n",
      "cite_ref-endgame_peak_16-4         https://web.archive.org/web/20191023105800/htt...\n",
      "cite_ref-80                        https://www.boxofficemojo.com/release/rl411726...\n",
      "cite_ref-toy_story_3_peak_74-1     https://web.archive.org/web/20110718213347/htt...\n",
      "cite_ref-81                           https://www.boxofficemojo.com/title/tt3469046/\n",
      "cite_ref-Beauty_peak_49-2          https://web.archive.org/web/20171211010216/htt...\n",
      "cite_ref-jp_82-0                   https://web.archive.org/web/20210126121145/htt...\n",
      "cite_ref-84                        https://web.archive.org/web/20220929163621/htt...\n",
      "cite_ref-Dory_peak_85-0            https://web.archive.org/web/20161225234827/htt...\n",
      "cite_ref-tpm_86-0                     https://www.boxofficemojo.com/title/tt0120915/\n",
      "cite_ref-titanic_peak_20-1         https://web.archive.org/web/20010716094602/htt...\n",
      "cite_ref-87                           https://www.boxofficemojo.com/title/tt1014759/\n",
      "cite_ref-Alice_peak_88-0           https://web.archive.org/web/20100701022108/htt...\n",
      "cite_ref-zootopia_89-0             https://www.boxofficemojo.com/releasegroup/gr1...\n",
      "cite_ref-civil_war_peak_56-1       https://web.archive.org/web/20160801231148/htt...\n",
      "cite_ref-90                           https://www.boxofficemojo.com/title/tt0903624/\n",
      "cite_ref-Hobbit_1_peak_91-0        https://web.archive.org/web/20130402221510/htt...\n",
      "cite_ref-hp1_92-0                      https://www.boxofficemojo.com/title/tt0241527\n",
      "cite_ref-HP1_peak_93-0             https://web.archive.org/web/20030402135656/htt...\n",
      "cite_ref-tdk_94-0                     https://www.boxofficemojo.com/title/tt0468569/\n",
      "cite_ref-TDK_peak_95-0             https://web.archive.org/web/20090228223109/htt...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# send request to the wikipedia page\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_highest-grossing_films'\n",
    "response = requests.get(url)\n",
    "\n",
    "# parse the html using beautiful soup and store in variable `soup`\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# find the table containing the references\n",
    "ref_table = soup.find('table', {'class': 'wikitable sortable plainrowheaders'})\n",
    "\n",
    "# extract the reference links and their corresponding external links\n",
    "ref_list = []\n",
    "for ref in ref_table.find_all('sup'):\n",
    "    ref_id = ref.get('id')\n",
    "    ref_link = ref.find('a')\n",
    "    if ref_id is not None and ref_link is not None and ref_link.get('href').startswith('#cite_note'):\n",
    "        # find the reference text element\n",
    "        ref_text = soup.find('li', {'id': ref_link.get('href')[1:]}).find('span', {'class': 'reference-text'})\n",
    "        if ref_text is not None:\n",
    "            # find the citation element\n",
    "            citation = ref_text.find('cite', {'class': 'citation web cs1'})\n",
    "            if citation is not None:\n",
    "                # find the external link\n",
    "                link = citation.find('a')\n",
    "                if link is not None:\n",
    "                    ref_list.append({'ID': ref_id, 'Link': link.get('href')})\n",
    "\n",
    "# create a dataframe from the list of dictionaries\n",
    "ref_df = pd.DataFrame(ref_list)\n",
    "\n",
    "# filter out rows where the ID doesn't end with '-0'\n",
    "ref_df = ref_df[ref_df['ID'].str.endswith('-0')]\n",
    "\n",
    "# create a dataframe from the list of dictionaries\n",
    "ref_df = pd.DataFrame(ref_list).iloc[1:].set_index('ID')\n",
    "\n",
    "# display the dataframe\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(ref_df)\n",
    "\n",
    "# Save the dataset as an excel file\n",
    "ref_df.to_excel(\"LINKS_REF_highest_grossing_films.xlsx\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2db55147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aquesta persona no existeix! Dona-li al botó per actualitzar la persona que no existeix\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4d0520b9f34b72be17c8863101f548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='Display Image', style=ButtonStyle()),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#EXERCICI 3\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# create container widget\n",
    "container = widgets.VBox()\n",
    "\n",
    "def display_image(button):\n",
    "    # fetch HTML from URL\n",
    "    url = 'https://thispersondoesnotexist.xyz/'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # extract image URL from HTML\n",
    "    img = soup.find('img', {'class': 'img-responsive'})\n",
    "    img_url = 'https://thispersondoesnotexist.xyz' + img['src']\n",
    "\n",
    "    # display image in container\n",
    "    image_widget = widgets.Image(value=requests.get(img_url).content)\n",
    "    container.children = [button, image_widget]\n",
    "\n",
    "# create button\n",
    "display_image_button = widgets.Button(description='Display Image')\n",
    "display_image_button.on_click(display_image)\n",
    "\n",
    "# add button to container\n",
    "container.children = [display_image_button]\n",
    "print(\"Aquesta persona no existeix! Dona-li al botó per actualitzar la persona que no existeix\")\n",
    "# display container\n",
    "display(container)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
